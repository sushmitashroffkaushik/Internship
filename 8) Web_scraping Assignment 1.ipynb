{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2efdaf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Header\n",
      "0                      Main Page\n",
      "1           Welcome to Wikipedia\n",
      "2  From today's featured article\n",
      "3               Did you know ...\n",
      "4                    In the news\n",
      "5                    On this day\n",
      "6       Today's featured picture\n",
      "7       Other areas of Wikipedia\n",
      "8    Wikipedia's sister projects\n",
      "9            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "header_tags = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])\n",
    "\n",
    "header_texts = [tag.get_text() for tag in header_tags]\n",
    "\n",
    "df = pd.DataFrame(header_texts, columns=[\"Header\"])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8059f954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of President and Term of office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind14th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee13th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil12th President of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam11th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan10th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma9th  President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman8th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh7th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy6th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed5th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri4th President of I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain3rd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan2nd President of I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad1st President of India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name of President and Term of office\n",
       "0         Shri Ram Nath Kovind14th President of India\n",
       "1        Shri Pranab Mukherjee13th President of India\n",
       "2   Smt Pratibha Devisingh Patil12th President of ...\n",
       "3       DR. A.P.J. Abdul Kalam11th President of India\n",
       "4         Shri K. R. Narayanan10th President of India\n",
       "5      Dr Shankar Dayal Sharma9th  President of India\n",
       "6           Shri R Venkataraman8th President of India\n",
       "7              Giani Zail Singh7th President of India\n",
       "8     Shri Neelam Sanjiva Reddy6th President of India\n",
       "9      Dr. Fakhruddin Ali Ahmed5th President of India\n",
       "10  Shri Varahagiri Venkata Giri4th President of I...\n",
       "11             Dr. Zakir Husain3rd President of India\n",
       "12  Dr. Sarvepalli Radhakrishnan2nd President of I...\n",
       "13          Dr. Rajendra Prasad1st President of India"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd\n",
    "pres = requests.get('https://presidentofindia.nic.in/former-presidents')\n",
    "\n",
    "pres\n",
    "\n",
    "in_pres = BeautifulSoup(pres.content)# Downloading the content of the webpage.\n",
    "in_pres\n",
    "\n",
    "name = [] # empty list to store \n",
    "for i in in_pres.find_all('div', class_=\"desc-sec\"):\n",
    "    name.append(i.text.replace('\\n',''))\n",
    "    \n",
    "name\n",
    "\n",
    "df_pres = pd.DataFrame({'Name of President and Term of office': name })\n",
    "df_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcb6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f24e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batting Details\n",
      "Country: NZ, Name: Kane WILLIAMSON, Rating: 859\n",
      "Country: ENGLAND, Name: Joe ROOT, Rating: 824\n",
      "Country: PAKISTAN, Name: Babar AZAM, Rating: 768\n",
      "Country: NEW ZEALAND, Name: Daryl MITCHELL, Rating: 768\n",
      "Country: AUSTRALIA, Name: Steve SMITH, Rating: 757\n",
      "Country: INDIA, Name: Rohit SHARMA, Rating: 751\n",
      "Country: SRI LANKA, Name: Dimuth KARUNARATNE, Rating: 750\n",
      "Country: INDIA, Name: Yashasvi JAISWAL, Rating: 740\n",
      "Country: INDIA, Name: Virat KOHLI, Rating: 737\n",
      "Country: ENGLAND, Name: Harry BROOK, Rating: 735\n",
      "Bowling Details\n",
      "Country: IND, Name: Ravichandran ASHWIN, Rating: 870\n",
      "Country: AUSTRALIA, Name: Josh HAZLEWOOD, Rating: 847\n",
      "Country: INDIA, Name: Jasprit BUMRAH, Rating: 847\n",
      "Country: SOUTH AFRICA, Name: Kagiso RABADA, Rating: 834\n",
      "Country: AUSTRALIA, Name: Pat CUMMINS, Rating: 820\n",
      "Country: AUSTRALIA, Name: Nathan LYON, Rating: 801\n",
      "Country: INDIA, Name: Ravindra JADEJA, Rating: 788\n",
      "Country: SRI LANKA, Name: Prabath JAYASURIYA, Rating: 783\n",
      "Country: ENGLAND, Name: James ANDERSON, Rating: 739\n",
      "Country: PAKISTAN, Name: Shaheen AFRIDI, Rating: 733\n"
     ]
    }
   ],
   "source": [
    "# Question 3 (b) (c)\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "driver = None\n",
    "def init_driver(url):\n",
    "    global driver\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\")\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    return driver\n",
    "\n",
    "def scrap_batting_details():\n",
    "  print(\"Batting Details\")\n",
    "  rows = driver.find_elements(By.CLASS_NAME, 'si-table-body')[0].find_elements(By.CLASS_NAME, 'si-table-row')\n",
    "  scrape_details(rows)\n",
    "\n",
    "def scrap_bowling_details():\n",
    "  print(\"Bowling Details\")\n",
    "  rows = driver.find_elements(By.CLASS_NAME, 'si-table-body')[1].find_elements(By.CLASS_NAME, 'si-table-row')\n",
    "  scrape_details(rows)\n",
    "    \n",
    "def scrape_details(rows):\n",
    "  for row in rows:\n",
    "    country = row.find_element(By.CSS_SELECTOR, 'span.si-sname').text.strip() or row.find_element(By.CSS_SELECTOR, 'span.si-fname').text.strip()\n",
    "    name = row.find_element(By.CSS_SELECTOR, 'a.si-player-name-wrap').text.strip()\n",
    "    name = \" \".join(name.split(\"\\n\"))\n",
    "    rating = row.find_element(By.CSS_SELECTOR, 'div.si-rating').text.strip()\n",
    "    print(f\"Country: {country}, Name: {name}, Rating: {rating}\")\n",
    "  return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        init_driver(\"https://www.icc-cricket.com/rankings/mens/player-rankings/test\")\n",
    "        if driver:\n",
    "          WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"si-table-body\"))\n",
    "          )\n",
    "          time.sleep(10)\n",
    "          scrap_batting_details()\n",
    "          scrap_bowling_details()\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47cb1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 (a) (b) (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1087b1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Headline        Time     News Link\n",
      "0   Skip Navigation  13 Min Ago  #MainContent\n",
      "1   Skip Navigation  13 Min Ago  #MainContent\n",
      "2   Skip Navigation  13 Min Ago  #MainContent\n",
      "3   Skip Navigation  13 Min Ago  #MainContent\n",
      "4   Skip Navigation  13 Min Ago  #MainContent\n",
      "5   Skip Navigation  13 Min Ago  #MainContent\n",
      "6   Skip Navigation  13 Min Ago  #MainContent\n",
      "7   Skip Navigation  13 Min Ago  #MainContent\n",
      "8   Skip Navigation  13 Min Ago  #MainContent\n",
      "9   Skip Navigation  13 Min Ago  #MainContent\n",
      "10  Skip Navigation  13 Min Ago  #MainContent\n",
      "11  Skip Navigation  13 Min Ago  #MainContent\n",
      "12  Skip Navigation  13 Min Ago  #MainContent\n",
      "13  Skip Navigation  13 Min Ago  #MainContent\n",
      "14  Skip Navigation  13 Min Ago  #MainContent\n",
      "15  Skip Navigation  13 Min Ago  #MainContent\n",
      "16  Skip Navigation  13 Min Ago  #MainContent\n",
      "17  Skip Navigation  13 Min Ago  #MainContent\n",
      "18  Skip Navigation  13 Min Ago  #MainContent\n",
      "19  Skip Navigation  13 Min Ago  #MainContent\n",
      "20  Skip Navigation  13 Min Ago  #MainContent\n",
      "21  Skip Navigation  13 Min Ago  #MainContent\n",
      "22  Skip Navigation  13 Min Ago  #MainContent\n",
      "23  Skip Navigation  13 Min Ago  #MainContent\n",
      "24  Skip Navigation  13 Min Ago  #MainContent\n",
      "25  Skip Navigation  13 Min Ago  #MainContent\n",
      "26  Skip Navigation  13 Min Ago  #MainContent\n",
      "27  Skip Navigation  13 Min Ago  #MainContent\n",
      "28  Skip Navigation  13 Min Ago  #MainContent\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the news articles on the page\n",
    "articles = soup.find_all(\"div\", class_=\"Card-titleContainer\")\n",
    "\n",
    "# Initialize empty lists to store the scraped data\n",
    "headlines = []\n",
    "times = []\n",
    "links = []\n",
    "\n",
    "# Loop through each article and extract the required information\n",
    "for article in articles:\n",
    "  # Extract the headline\n",
    "  headline = soup.find(\"a\").text.strip()\n",
    "  headlines.append(headline)\n",
    "  \n",
    "  # Extract the time\n",
    "  time = soup.find(\"time\").text.strip()\n",
    "  times.append(time)\n",
    "  \n",
    "  # Extract the news link\n",
    "  link = soup.find(\"a\")[\"href\"]\n",
    "  links.append(link)\n",
    "\n",
    "# Create a dataframe using the scraped data\n",
    "data = {\n",
    "  \"Headline\": headlines,\n",
    "  \"Time\": times,\n",
    "  \"News Link\": links\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f242da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AACE Clinical Case Reports, Authors: NA, Published Date: NA, Paper URL: AACE Clinical Case Reports\n",
      "Title: AASRI Procedia, Authors: NA, Published Date: NA, Paper URL: AASRI Procedia\n",
      "Title: Ab Initio Valence Calculations in Chemistry, Authors: NA, Published Date: •  1974, Paper URL: Ab Initio Valence Calculations in Chemistry\n",
      "Title: Abatement of Environmental Pollutants, Authors: NA, Published Date: •  2019, Paper URL: Abatement of Environmental Pollutants\n",
      "Title: Abbreviated Guide, Authors: NA, Published Date: •  1990, Paper URL: Abbreviated Guide\n",
      "Title: ABC Proteins, Authors: NA, Published Date: •  2003, Paper URL: ABC Proteins\n",
      "Title: Abelian Groups (Third Edition), Authors: NA, Published Date: •  1960, Paper URL: Abelian Groups (Third Edition)\n",
      "Title: Abeloff's Clinical Oncology (Fifth Edition), Authors: NA, Published Date: •  2014, Paper URL: Abeloff's Clinical Oncology (Fifth Edition)\n",
      "Title: Abeloff's Clinical Oncology (Sixth Edition), Authors: NA, Published Date: •  2020, Paper URL: Abeloff's Clinical Oncology (Sixth Edition)\n",
      "Title: Abernathy's Surgical Secrets (Sixth Edition), Authors: NA, Published Date: •  2009, Paper URL: Abernathy's Surgical Secrets (Sixth Edition)\n",
      "Title: Abernathy's Surgical Secrets (Seventh Edition), Authors: NA, Published Date: •  2017, Paper URL: Abernathy's Surgical Secrets (Seventh Edition)\n",
      "Title: The Abilities and Achievements of Orientals in North America, Authors: NA, Published Date: •  1982, Paper URL: The Abilities and Achievements of Orientals in North America\n",
      "Title: Abiotic and Biotic Stresses in Soybean Production, Authors: NA, Published Date: •  2016, Paper URL: Abiotic and Biotic Stresses in Soybean Production\n",
      "Title: Abiotic Stress and Legumes, Authors: NA, Published Date: •  2021, Paper URL: Abiotic Stress and Legumes\n",
      "Title: Abiotic Stresses in Wheat, Authors: NA, Published Date: •  2023, Paper URL: Abiotic Stresses in Wheat\n",
      "Title: Ableton Live 8 and Suite 8, Authors: NA, Published Date: •  2009, Paper URL: Ableton Live 8 and Suite 8\n",
      "Title: L'abord vasculaire pour hémodialyse (Deuxième Édition), Authors: NA, Published Date: •  2009, Paper URL: L'abord vasculaire pour hémodialyse (Deuxième Édition)\n",
      "Title: Abortion and Sterilization, Authors: NA, Published Date: •  1981, Paper URL: Abortion and Sterilization\n",
      "Title: Above Ground Storage Tank Oil Spills, Authors: NA, Published Date: •  2022, Paper URL: Above Ground Storage Tank Oil Spills\n",
      "Title: Abrasive Water Jet Perforation and Multi-Stage Fracturing, Authors: NA, Published Date: •  2018, Paper URL: Abrasive Water Jet Perforation and Multi-Stage Fracturing\n",
      "Title: Abridged Science for High School Students, Authors: NA, Published Date: •  1966, Paper URL: Abridged Science for High School Students\n",
      "Title: Abridged Science for High School Students, Authors: NA, Published Date: •  1966, Paper URL: Abridged Science for High School Students\n",
      "Title: Abschlusskurs Sonografie der Bewegungsorgane First Edition, Authors: NA, Published Date: •  2024, Paper URL: Abschlusskurs Sonografie der Bewegungsorgane First Edition\n",
      "Title: Absolute Radiometry, Authors: NA, Published Date: •  1989, Paper URL: Absolute Radiometry\n",
      "Title: Absorption, Authors: NA, Published Date: •  1993, Paper URL: Absorption\n",
      "Title: Absorption-Based Post-Combustion Capture of Carbon Dioxide, Authors: NA, Published Date: •  2016, Paper URL: Absorption-Based Post-Combustion Capture of Carbon Dioxide\n",
      "Title: Absorption Spectra and Chemical Bonding in Complexes, Authors: NA, Published Date: •  1962, Paper URL: Absorption Spectra and Chemical Bonding in Complexes\n",
      "Title: Abstract Domains in Constraint Programming, Authors: NA, Published Date: •  2015, Paper URL: Abstract Domains in Constraint Programming\n",
      "Title: Abstracts and Abstracting, Authors: NA, Published Date: •  2010, Paper URL: Abstracts and Abstracting\n",
      "Title: AC Power Conditioners, Authors: NA, Published Date: •  1990, Paper URL: AC Power Conditioners\n",
      "Title: Academia to Biotechnology, Authors: NA, Published Date: •  2005, Paper URL: Academia to Biotechnology\n",
      "Title: From Academia to Entrepreneur, Authors: NA, Published Date: •  2014, Paper URL: From Academia to Entrepreneur\n",
      "Title: Academic Branch Libraries in Changing Times, Authors: NA, Published Date: •  2011, Paper URL: Academic Branch Libraries in Changing Times\n",
      "Title: Academic Crowdsourcing in the Humanities, Authors: NA, Published Date: •  2018, Paper URL: Academic Crowdsourcing in the Humanities\n",
      "Title: The Academic Librarian as Blended Professional, Authors: NA, Published Date: •  2016, Paper URL: The Academic Librarian as Blended Professional\n",
      "Title: Academic Libraries and Public Engagement with Science and Technology, Authors: NA, Published Date: •  2019, Paper URL: Academic Libraries and Public Engagement with Science and Technology\n",
      "Title: Academic Libraries and Toxic Leadership, Authors: NA, Published Date: •  2017, Paper URL: Academic Libraries and Toxic Leadership\n",
      "Title: Academic Libraries in the US and China, Authors: NA, Published Date: •  2013, Paper URL: Academic Libraries in the US and China\n",
      "Title: Academic Pathology, Authors: NA, Published Date: NA, Paper URL: Academic Pathology\n",
      "Title: Academic Pediatrics, Authors: NA, Published Date: NA, Paper URL: Academic Pediatrics\n",
      "Title: Academic Press Library in Mobile and Wireless Communications, Authors: NA, Published Date: •  2016, Paper URL: Academic Press Library in Mobile and Wireless Communications\n",
      "Title: Academic Press Library in Signal Processing, Authors: NA, Published Date: NA, Paper URL: Academic Press Library in Signal Processing\n",
      "Title: Academic Press Library in Signal Processing, Volume 6, Authors: NA, Published Date: •  2018, Paper URL: Academic Press Library in Signal Processing, Volume 6\n",
      "Title: Academic Press Library in Signal Processing, Volume 7, Authors: NA, Published Date: •  2018, Paper URL: Academic Press Library in Signal Processing, Volume 7\n",
      "Title: Academic and Professional Publishing, Authors: NA, Published Date: •  2012, Paper URL: Academic and Professional Publishing\n",
      "Title: Academic Quality and Integrity in the New Higher Education Digital Environment, Authors: NA, Published Date: •  2023, Paper URL: Academic Quality and Integrity in the New Higher Education Digital Environment\n",
      "Title: Academic Radiology, Authors: NA, Published Date: NA, Paper URL: Academic Radiology\n",
      "Title: The Academic Research Library in a Decade of Change, Authors: NA, Published Date: •  2007, Paper URL: The Academic Research Library in a Decade of Change\n",
      "Title: Academic Search Engines, Authors: NA, Published Date: •  2014, Paper URL: Academic Search Engines\n",
      "Title: Academic Voices, Authors: NA, Published Date: •  2022, Paper URL: Academic Voices\n",
      "Title: ACC Current Journal Review, Authors: NA, Published Date: NA, Paper URL: ACC Current Journal Review\n",
      "Title: Accelerated Bridge Construction, Authors: NA, Published Date: •  2015, Paper URL: Accelerated Bridge Construction\n",
      "Title: Accelerated Predictive Stability, Authors: NA, Published Date: •  2018, Paper URL: Accelerated Predictive Stability\n",
      "Title: Accelerated Quality and Reliability Solutions, Authors: NA, Published Date: •  2006, Paper URL: Accelerated Quality and Reliability Solutions\n",
      "Title: Accelerated Testing and Validation, Authors: NA, Published Date: •  2004, Paper URL: Accelerated Testing and Validation\n",
      "Title: Accelerating MATLAB with GPU Computing, Authors: NA, Published Date: •  2014, Paper URL: Accelerating MATLAB with GPU Computing\n",
      "Title: Accelerating Strategic Changes for Digital Transformation in the Healthcare Industry, Authors: NA, Published Date: •  2023, Paper URL: Accelerating Strategic Changes for Digital Transformation in the Healthcare Industry\n",
      "Title: The Accelerating Transport Innovation Revolution, Authors: NA, Published Date: •  2019, Paper URL: The Accelerating Transport Innovation Revolution\n",
      "Title: Accelerator Health Physics, Authors: NA, Published Date: •  1973, Paper URL: Accelerator Health Physics\n",
      "Title: Acceptance and Commitment Therapy, Authors: NA, Published Date: •  2019, Paper URL: Acceptance and Commitment Therapy\n",
      "Title: Access All Areas, Authors: NA, Published Date: •  2007, Paper URL: Access All Areas\n",
      "Title: Access Control and Personal Identification Systems, Authors: NA, Published Date: •  1988, Paper URL: Access Control and Personal Identification Systems\n",
      "Title: Accident Analysis & Prevention, Authors: NA, Published Date: NA, Paper URL: Accident Analysis & Prevention\n",
      "Title: Accident and Emergency Nursing, Authors: NA, Published Date: NA, Paper URL: Accident and Emergency Nursing\n",
      "Title: Accident & Emergency Radiology (Second Edition), Authors: NA, Published Date: •  2005, Paper URL: Accident & Emergency Radiology (Second Edition)\n",
      "Title: Accident Proneness, Authors: NA, Published Date: •  1971, Paper URL: Accident Proneness\n",
      "Title: Accident-Tolerant Materials for Light Water Reactor Fuels, Authors: NA, Published Date: •  2020, Paper URL: Accident-Tolerant Materials for Light Water Reactor Fuels\n",
      "Title: Accidental Information Discovery, Authors: NA, Published Date: •  2016, Paper URL: Accidental Information Discovery\n",
      "Title: Accountability in Human Resource Management, Authors: NA, Published Date: •  1995, Paper URL: Accountability in Human Resource Management\n",
      "Title: Accounting in Business (Fifth Edition), Authors: NA, Published Date: •  1984, Paper URL: Accounting in Business (Fifth Edition)\n",
      "Title: Accounting Education for the 21st Century, Authors: NA, Published Date: •  1994, Paper URL: Accounting Education for the 21st Century\n",
      "Title: Accounting and Finance for the International Hospitality Industry, Authors: NA, Published Date: •  1998, Paper URL: Accounting and Finance for the International Hospitality Industry\n",
      "Title: Accounting and Financial Management, Authors: NA, Published Date: •  2006, Paper URL: Accounting and Financial Management\n",
      "Title: Accounting Forum, Authors: NA, Published Date: NA, Paper URL: Accounting Forum\n",
      "Title: Accounting, Management and Information Technologies, Authors: NA, Published Date: NA, Paper URL: Accounting, Management and Information Technologies\n",
      "Title: Accounting in a Nutshell (Third Edition), Authors: NA, Published Date: •  2009, Paper URL: Accounting in a Nutshell (Third Edition)\n",
      "Title: Accounting, Organizations and Society, Authors: NA, Published Date: NA, Paper URL: Accounting, Organizations and Society\n",
      "Title: Accounting for Price-Level Changes, Authors: NA, Published Date: •  1966, Paper URL: Accounting for Price-Level Changes\n",
      "Title: Accounting Principles and Practice, Authors: NA, Published Date: •  1964, Paper URL: Accounting Principles and Practice\n",
      "Title: Accounting Theory and Practice, Authors: NA, Published Date: NA, Paper URL: Accounting Theory and Practice\n",
      "Title: An Accounting Thesaurus, Authors: NA, Published Date: •  1995, Paper URL: An Accounting Thesaurus\n",
      "Title: Accurate Results in the Clinical Laboratory, Authors: NA, Published Date: •  2013, Paper URL: Accurate Results in the Clinical Laboratory\n",
      "Title: Accurate Results in the Clinical Laboratory (Second Edition), Authors: NA, Published Date: •  2019, Paper URL: Accurate Results in the Clinical Laboratory (Second Edition)\n",
      "Title: Acetylcholine, Authors: NA, Published Date: •  1973, Paper URL: Acetylcholine\n",
      "Title: Achieve Lasting Process Improvement, Authors: NA, Published Date: •  2002, Paper URL: Achieve Lasting Process Improvement\n",
      "Title: Achievements in the Life Sciences, Authors: NA, Published Date: NA, Paper URL: Achievements in the Life Sciences\n",
      "Title: Achieving Inclusive Growth in China Through Vertical Specialization, Authors: NA, Published Date: •  2016, Paper URL: Achieving Inclusive Growth in China Through Vertical Specialization\n",
      "Title: Achieving Market Integration, Authors: NA, Published Date: •  2004, Paper URL: Achieving Market Integration\n",
      "Title: Achieving the Perfect Fit, Authors: NA, Published Date: •  1998, Paper URL: Achieving the Perfect Fit\n",
      "Title: Achieving Transformational Change in Academic Libraries, Authors: NA, Published Date: •  2013, Paper URL: Achieving Transformational Change in Academic Libraries\n",
      "Title: Acidic Proteins of the Nucleus, Authors: NA, Published Date: •  1974, Paper URL: Acidic Proteins of the Nucleus\n",
      "Title: Acidosis, Authors: NA, Published Date: •  1946, Paper URL: Acidosis\n",
      "Title: ACL Injuries in Female Athletes, Authors: NA, Published Date: •  2019, Paper URL: ACL Injuries in Female Athletes\n",
      "Title: Acoelomate and Pseudocoelomate Metazoans, Authors: NA, Published Date: •  1974, Paper URL: Acoelomate and Pseudocoelomate Metazoans\n",
      "Title: ACOG Clinical Review, Authors: NA, Published Date: NA, Paper URL: ACOG Clinical Review\n",
      "Title: ACOPS Yearbook 1986–87, Authors: NA, Published Date: •  1987, Paper URL: ACOPS Yearbook 1986–87\n",
      "Title: Les Acouphenes, Authors: NA, Published Date: •  2017, Paper URL: Les Acouphenes\n",
      "Title: The Acoustic Bubble, Authors: NA, Published Date: •  1994, Paper URL: The Acoustic Bubble\n",
      "Title: Acoustic Communication in Birds, Authors: NA, Published Date: •  1983, Paper URL: Acoustic Communication in Birds\n",
      "Title: Acoustic Design, Authors: NA, Published Date: •  1987, Paper URL: Acoustic Design\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = None\n",
    "def init_driver(url):\n",
    "    global driver\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "        # options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\")\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    return driver\n",
    "\n",
    "def scrape_details():\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, 'li.js-publication')\n",
    "    for row in rows:\n",
    "        title = row.find_element(By.CLASS_NAME, 'js-publication-title').text.strip()\n",
    "        authors = \"NA\"\n",
    "        p_date = \"NA\"\n",
    "        try:\n",
    "            p_date = row.find_element(By.CLASS_NAME, 'js-publication-year').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        url = row.find_element(By.CLASS_NAME, 'js-publication-title').text.strip()\n",
    "        print(f\"Title: {title}, Authors: {authors}, Published Date: {p_date}, Paper URL: {url}\")\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        init_driver(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "        if driver:\n",
    "            scrape_details()\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3665b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Name  \\\n",
      "0                 Castle's Barbeque   \n",
      "1                        Cafe Knosh   \n",
      "2                       India Grill   \n",
      "3              The Barbeque Company   \n",
      "4                    Delhi Barbeque   \n",
      "5  The Monarch - Bar Be Que Village   \n",
      "6                The Barbeque Times   \n",
      "\n",
      "                                         Cuisine  \\\n",
      "0                           Chinese,North Indian   \n",
      "1                            Italian,Continental   \n",
      "2                           North Indian,Italian   \n",
      "3                           North Indian,Chinese   \n",
      "4                                   North Indian   \n",
      "5                                   North Indian   \n",
      "6  North Indian,Continental,Chinese,South Indian   \n",
      "\n",
      "                                            Location Rating  \\\n",
      "0                     Connaught Place, Central Delhi      4   \n",
      "1  The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
      "2               Hilton Garden Inn,Saket, South Delhi    3.9   \n",
      "3                 Gardens Galleria,Sector 38A, Noida    3.9   \n",
      "4     Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
      "5  Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
      "6              M2K Corporate Park,Sector 51, Gurgaon    4.1   \n",
      "\n",
      "                                           Image URL  \n",
      "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
      "6  https://im1.dineout.co.in/images/uploads/resta...  \n"
     ]
    }
   ],
   "source": [
    "# Question 7\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.dineout.co.in/delhi-restaurants/buffet-special\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "rows = soup.find('div', class_='restnt-card-wrap-new')\n",
    "\n",
    "rest_name = []\n",
    "rest_cuisine = []\n",
    "rest_location = []\n",
    "rest_rating = []\n",
    "rest_img = []\n",
    "\n",
    "for row in rows: \n",
    "  rest_img.append(row.find('img').get('data-src'))\n",
    "  rest_name.append(row.find('a', class_='restnt-name').text.strip())\n",
    "  rest_location.append(row.find('div', class_='restnt-loc').text.strip())\n",
    "  rest_rating.append(row.find('div', class_='restnt-rating').text.strip())\n",
    "  cuisine = [x.text.strip() for x in row.find('div', class_='detail-info').find('span', class_='double-line-ellipsis').find_all('a')]\n",
    "  rest_cuisine.append(\",\".join(cuisine))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': rest_name,\n",
    "    'Cuisine': rest_cuisine,\n",
    "    'Location': rest_location,\n",
    "    'Rating': rest_rating,\n",
    "    'Image URL': rest_img,\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a86e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
